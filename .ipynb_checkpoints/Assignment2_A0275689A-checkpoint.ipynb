{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52fj0bRuXgvu"
   },
   "source": [
    "# Assignment 2: SoC Module Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjjJg5d_Xgvw"
   },
   "source": [
    "## Instructions to submit the assignment\n",
    "\n",
    "- Name your jupyter notebook as `Assignment2_[StudentID].ipynb`. For instance: `Assignment2_A0123873A.ipynb`\n",
    "- Your solution notebook must contain the python code that we can run to verify the answers.\n",
    "  - late within 1 hour: 10% reduction in grade\n",
    "  - late within 6 hours: 30% reduction in grade\n",
    "  - late within 12 hours: 50% reduction in grade\n",
    "  - late within 1 days: 70% reduction in grade\n",
    "  - after 1 days: zero mark\n",
    "- **This is an individual assessment. Refrain from working in groups.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTnGjmPVXgvy"
   },
   "source": [
    "In this assignment we design a recomendation engine (*Don't worry about the effectiveness of the system. It maybe very bad. The idea is just to offer you a proof of concept!*). The recommendation engine suggests the students a module that closely matches the modules already taken by the student. The dataset comprices of two files:\n",
    "- List of modules in the School of Computing \n",
    "- List of graduated students and the modules they had taken during their studies\n",
    "\n",
    "Schematic diagram of the entire process is shown as below:\n",
    "\n",
    "![Schema]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgL9CZ-pXgvz"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Tjl54HB5Xgvz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ignore specific UserWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "'''\n",
    "    YOU MUST USE THE RANDOM SEED WHEREVER NEEDED OR RANDOM_STATE as 42.\n",
    "'''\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "courses = pd.read_csv(\"courses.tsv\", sep='\\t')\n",
    "students = pd.read_csv(\"students.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKrejjTxXgv0"
   },
   "source": [
    "# Question 1: Creating the preprocessing pipeline (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQ_EU5o9Xgv1"
   },
   "source": [
    "We want to create a sklearn pipeline to efficiently preprocess the data and prepare it for training a model. We use three different features in the `courses` data: `specialisation`, `info` and `workload`. We want to represent every feature in a numeric form and merge them to form a feature vector for every course. We do so in the following way:\n",
    "- `specialisation` represents one of the six levels of the module. For instance: CS2103 is a Software Engineering (SE) specialisation module. Encode this categorical feature into a vector. The decision of handling missing values is left to you! *(Hint: You can use `MultiLabelBinerizer` to do so.)*\n",
    "- `info` provides a short discription of the module. We want to convert it into a vector using CountVectorizer. *Don't forget to remove the stopwords* while doing so.\n",
    "-  `workload` states the intended distribution of workload over lectures, tutorials, labs and self study. We want to find the workload as the sum of individual workloads. For instnce: 3-1-1-3-2 workload transforms to 10 hours.\n",
    "\n",
    "Provide implementation for three classes that help us build the pipeline. `transformed_courses` should be a numpy array of shape `[n_courses X n_features]`.\n",
    "\n",
    "                                                                                                   (6 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sVBlKTN6Xgv1"
   },
   "outputs": [],
   "source": [
    "class WorkloadTransformer:        \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None, **fit_params):\n",
    "        \n",
    "        #split '-' and calculate the sum, trun into a numpy array\n",
    "        tmp = X['workload'].str.strip().str.split('-').apply(lambda x : sum(map(float,x))).to_numpy().reshape(-1,1)\n",
    "\n",
    "        return tmp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EZ_fhJkFXgv2"
   },
   "outputs": [],
   "source": [
    "class InfoTransformer:        \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        stop = stopwords.words('english')\n",
    "        self.count_vect = CountVectorizer(stop_words = stop).fit(X['info'])\n",
    "        return self\n",
    "     \n",
    "    def transform(self, X, y = None, **fit_params):\n",
    "        \n",
    "        info_count = self.count_vect.transform(X['info']).toarray()\n",
    "        \n",
    "        return info_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oLKGAPR1Xgv3"
   },
   "outputs": [],
   "source": [
    "class SpecTransformer:       \n",
    "        \n",
    "    def fit(self, X, y = None, **fit_params):    \n",
    "        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.mlb.fit(X['specialisation'].fillna('None').tolist())\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None, **fit_params):\n",
    "        \n",
    "\n",
    "        return self.mlb.transform(X['specialisation'].fillna('None').tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 2217)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureTransformer = FeatureUnion([\n",
    "    ('workload_processing', Pipeline([('wrkld', WorkloadTransformer())])),\n",
    "    ('info_processing', Pipeline([('info', InfoTransformer())])),\n",
    "    ('spec_processing', Pipeline([('spec', SpecTransformer())]))\n",
    "])\n",
    "\n",
    "featureTransformer.fit(courses)\n",
    "transformeed_courses = featureTransformer.transform(courses)\n",
    "transformeed_courses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xtc4ObIlXgv5"
   },
   "source": [
    "Now we prepare our testing data in the same way we preprocessed the course. `students` data comprises of 1000 students and a list of modules they have taken. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQu6wIgYXgv6"
   },
   "source": [
    "Create `Xtest` and `Ytest` as two matrices. `Xtest`, of size `1000*5`, comprises of first five modules for every student in the list. `Ytest`, of size `1000*[remaining_modules]`, comprises of rest of the modules for every student in the list. \n",
    "We do so in order to assess the performance of the recommender. We assess the recommender based on its effectiveness to predict the modules given a list of five modules as the input.\n",
    "\n",
    "For instance: \n",
    "- `Xtest[0] = ['CS2105', 'CS4222', 'CS6270', 'CS6205', 'CS4226']`\n",
    "- `Ytest[0] = ['CS3282', 'CS6204', 'CS5223', 'CS3281', 'CS4344', 'CS5422', 'CS3237', 'CS5233']`.\n",
    "\n",
    "<div align=\"right\">(2 marks)</align>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "R2t2xUhYXgv6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5)\n",
      "(1000, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['CS5422', 'CS5223', 'CS4237', 'CS3281', 'CS6213'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "Xtest = students['courses'].str.split(\",\" ,expand=True).values[:,:5]\n",
    "print(Xtest.shape)\n",
    "\n",
    "\n",
    "Ytest = students['courses'].str.split(\",\", expand=True).values[:,5:]\n",
    "print(Ytest.shape)\n",
    "Xtest[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8-D7LhvXgv7"
   },
   "source": [
    "For every student in `Xtest`, we need to transform the list of 5 modules to the feature space using the `featureTransformer` fit on the training data. For every module we will get a feature vector of size `n_features`. We *add* these feature vectors to get an aggregate feature vector for very student.\n",
    "\n",
    "Write a function `getFeatureVector` that takes in the list of modules and `featureTransformer`. It returns the feature vector for the specified list of courses. For instance, `getFeatureVector(Xtest[0], featureTransformer)` will return a vector of size `n_features`.\n",
    "\n",
    "<div align=\"right\">(2 marks)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1FaBqoBPXgv7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2217,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getFeatureVector(modules, featureTransformer):\n",
    "     #featureTransformer:should use courses table\n",
    "    modules_in_courses = courses[courses['code'].isin(modules)]\n",
    "    vector = featureTransformer.transform(modules_in_courses).sum(axis = 0)\n",
    "    return vector\n",
    "\n",
    "getFeatureVector(Xtest[0],featureTransformer).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuwxpWB2Xgv7"
   },
   "source": [
    "# Question 2: Content based recommender (4 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJbpI-xdXgv8"
   },
   "source": [
    "We can use a model as simple as K-nearest neighbour (KNN) to perform a content based recommendation. If we provide a list of 5 modules to the recommender, it provide us a list of modules that are similar to the specified modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQEMNzrcXgv8"
   },
   "source": [
    "`sklearn` provides `NearestNeighbors` as well as `KNeighborsClassifier`, both of which have a similar functionality. `NearestNeighbors` provides as an easy functionality to predict a list of K nearest neighbours. Therefore, we prefer it over `KNeighborsClassifier`. If we want to find K nearest points to a datapoint`d`, we need to use `n_neighbors` as K + 1 because the list includes `d` itself.\n",
    "\n",
    "You can now train the model using the training data, which comprises of `transformed_courses` and with their codes as the labels. \n",
    "<div align=\"right\">(1 mark)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ezqrA0XsXgv8"
   },
   "outputs": [],
   "source": [
    "K = 5\n",
    "model = NearestNeighbors(algorithm = \"brute\", n_neighbors = K + 1).fit(transformeed_courses)\n",
    "## Write your code here\n",
    "#model.fit(transformeed_courses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_Oo47yaXgv9"
   },
   "source": [
    "It is time to see our model in action. Let's see what modules our model reommends based on the modules taken by a student.\n",
    "\n",
    "Write a function that takes in a *pre-trained* model of your choice as input and the list of modules. It returns the top-K recommendations of the model. Print the top 6 recommendations for the first student. \n",
    "<div align=\"right\">(3 marks)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wH0yg5I6Xgv9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CS3203' 'CS3205' 'CS5223' 'CS2020' 'CS3216' 'CS6213']\n"
     ]
    }
   ],
   "source": [
    "def recommend(model, modulesTaken, k ):\n",
    "    modulesTaken_vector = getFeatureVector(modulesTaken,featureTransformer).reshape(1,-1)\n",
    "    distances, idx = model.kneighbors( modulesTaken_vector ,k)\n",
    "    idx = idx.ravel()\n",
    "    recommendations = courses.loc[idx,'code'] \n",
    "    return recommendations.values\n",
    "\n",
    "print(recommend(model, Xtest[0], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVVhPPoPXgv9"
   },
   "source": [
    "# Question 3: Recommender evaluation (6 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrxDQQWCXgv-"
   },
   "source": [
    "Is this the model any good? To assess the performance of the model, we use **precision** and **recall** as our metrics. `Ytest` consists of true labels for every students. Using those labels as the ground truth, compute the precision and recall for every student. Write a code that prints values of average precision and recall for a specific value of `K` over the `students` dataset. Print the value of average precision and average recall for `K= 10`.\n",
    "\n",
    "                                                                                                     (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average precision is:  0.056799999999999996\n",
      "The average recall is:  0.05652216743954361\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "def recom_evaluation(model,X,Y, k):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    for i in range(X.shape[0]):\n",
    "        y_pred = recommend(model, X[i], k)\n",
    "        y =[w for w in Y[i] if w is not None]  # filter out the None value\n",
    "        precision = len(set(y_pred)& set(y))/len(y_pred)\n",
    "        precision_list.append(precision)\n",
    "\n",
    "        recall = len(set(y_pred)& set(y))/len(y)\n",
    "        recall_list.append(recall)\n",
    "    \n",
    "    precision_list = np.array(precision_list)\n",
    "    precision = precision_list.mean()\n",
    "\n",
    "    recall_list = np.array(recall_list)\n",
    "    recall = recall_list.mean()\n",
    "    return precision, recall\n",
    "\n",
    "pre, rec = recom_evaluation(model,Xtest,Ytest,10)\n",
    "print(\"The average precision is: \",pre)\n",
    "print(\"The average recall is: \",rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeR2w7IpXgv-"
   },
   "source": [
    "We observe that both precision and recall is not really great. The reason might be igh feature dimension, which may even be noisy. Append the exisiting `featureTransformer` with a PCA to reduce the dimension. \n",
    "\n",
    "Print the value of average precision and recall for `K= 10` after the introduction of PCA.\n",
    "\n",
    "                                                                                                     (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 184)\n",
      "The average precision after the introduction of PCA is:  0.1195\n",
      "The average recall after the introduction of PCA is:  0.12975396668604872\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "featureTransformer = Pipeline([('feats',featureTransformer),('pca',pca)])\n",
    "pca_courses = featureTransformer.fit_transform(courses)\n",
    "print(pca_courses.shape)\n",
    "\n",
    "model2 = NearestNeighbors(algorithm = \"brute\", n_neighbors = 10).fit(pca_courses)\n",
    "pre, rec = recom_evaluation(model2,Xtest,Ytest,10)\n",
    "print(\"The average precision after the introduction of PCA is: \",pre)\n",
    "print(\"The average recall after the introduction of PCA is: \",rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih2GatUQXgv_"
   },
   "source": [
    "Can you provide some **concrete** (something that you can implement) suggestions to improve the performance of the system? The improvement does not have to be very significant.\n",
    "\n",
    "                                                                                                    (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XzTUXzCnXgv_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of courses with missing specialisation:  30\n",
      "the total number of courses:  184\n",
      "the missing percentage of specialisation： 0.16304347826086957\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "missing_number = courses['specialisation'].isna().sum()\n",
    "total_number = len(courses['specialisation'])\n",
    "print('the number of courses with missing specialisation: ',missing_number)\n",
    "print('the total number of courses: ',total_number)\n",
    "print('the missing percentage of specialisation：',missing_number/total_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specialisation of 30 courses have missing values, which account for 16% of the total courses. This would lead to these courses can't be effectively clustered by its specialisation due to the NaN.In order to improve it, people can manually track these missing values and add its specialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'module': 1224,\n",
       " 'introduces': 1047,\n",
       " 'fundamental': 838,\n",
       " 'concepts': 373,\n",
       " 'problem': 1469,\n",
       " 'solving': 1788,\n",
       " 'computing': 371,\n",
       " 'programming': 1490,\n",
       " 'using': 2026,\n",
       " 'imperative': 961,\n",
       " 'language': 1079,\n",
       " 'foremost': 812,\n",
       " 'introductory': 1050,\n",
       " 'course': 446,\n",
       " 'series': 1729,\n",
       " 'includes': 977,\n",
       " 'cs1020': 476,\n",
       " 'cs2010': 478,\n",
       " 'topics': 1951,\n",
       " 'covered': 450,\n",
       " 'include': 975,\n",
       " 'writing': 2104,\n",
       " 'pseudo': 1520,\n",
       " 'codes': 308,\n",
       " 'basic': 169,\n",
       " 'formulation': 821,\n",
       " 'program': 1485,\n",
       " 'development': 566,\n",
       " 'coding': 309,\n",
       " 'testing': 1920,\n",
       " 'debugging': 512,\n",
       " 'constructs': 405,\n",
       " 'variables': 2037,\n",
       " 'types': 1989,\n",
       " 'expressions': 755,\n",
       " 'assignments': 128,\n",
       " 'functions': 837,\n",
       " 'control': 420,\n",
       " 'structures': 1844,\n",
       " 'data': 495,\n",
       " 'arrays': 114,\n",
       " 'strings': 1840,\n",
       " 'simple': 1758,\n",
       " 'file': 789,\n",
       " 'processing': 1475,\n",
       " 'recursion': 1584,\n",
       " 'appropriate': 96,\n",
       " 'soc': 1778,\n",
       " 'students': 1847,\n",
       " 'equivalent': 697,\n",
       " 'cs1010': 473,\n",
       " 'cs1010s': 475,\n",
       " 'cs1010e': 474,\n",
       " 'methodology': 1200,\n",
       " 'taught': 1894,\n",
       " 'python': 1530,\n",
       " 'cs1020e': 477,\n",
       " 'foe': 806,\n",
       " 'comp': 331,\n",
       " 'ec': 630,\n",
       " 'fos': 823,\n",
       " 'computational': 366,\n",
       " 'starting': 1817,\n",
       " 'small': 1774,\n",
       " 'core': 434,\n",
       " 'abstractions': 8,\n",
       " 'method': 1199,\n",
       " 'communicating': 327,\n",
       " 'processes': 1474,\n",
       " 'begins': 175,\n",
       " 'purely': 1526,\n",
       " 'functional': 836,\n",
       " 'based': 167,\n",
       " 'substitution': 1857,\n",
       " 'execution': 727,\n",
       " 'model': 1218,\n",
       " 'ends': 674,\n",
       " 'powerful': 1429,\n",
       " 'modern': 1222,\n",
       " 'realistic': 1567,\n",
       " 'environment': 693,\n",
       " 'abstraction': 7,\n",
       " 'higher': 922,\n",
       " 'order': 1323,\n",
       " 'algorithmic': 55,\n",
       " 'strategies': 1833,\n",
       " 'state': 1819,\n",
       " 'mutation': 1246,\n",
       " 'loops': 1138,\n",
       " 'evaluation': 707,\n",
       " 'sorting': 1789,\n",
       " 'searching': 1694,\n",
       " 'second': 1695,\n",
       " 'continues': 416,\n",
       " 'introduction': 1049,\n",
       " 'emphasises': 656,\n",
       " 'object': 1288,\n",
       " 'oriented': 1332,\n",
       " 'application': 87,\n",
       " 'modeling': 1219,\n",
       " 'objects': 1290,\n",
       " 'classes': 286,\n",
       " 'methods': 1201,\n",
       " 'structure': 1842,\n",
       " 'implementation': 963,\n",
       " 'strageties': 1831,\n",
       " 'encapsulation': 667,\n",
       " 'use': 2019,\n",
       " 'apis': 83,\n",
       " 'class': 285,\n",
       " 'libraries': 1104,\n",
       " 'exception': 720,\n",
       " 'handling': 899,\n",
       " 'lists': 1122,\n",
       " 'linked': 1117,\n",
       " 'stacks': 1811,\n",
       " 'queues': 1539,\n",
       " 'hash': 904,\n",
       " 'tables': 1885,\n",
       " 'design': 552,\n",
       " 'various': 2042,\n",
       " 'forms': 819,\n",
       " 'recursive': 1585,\n",
       " 'algorithms': 56,\n",
       " 'big': 186,\n",
       " 'notation': 1281,\n",
       " 'mathematical': 1172,\n",
       " 'tools': 1948,\n",
       " 'required': 1623,\n",
       " 'study': 1850,\n",
       " 'computer': 369,\n",
       " 'science': 1684,\n",
       " 'aims': 51,\n",
       " 'train': 1960,\n",
       " 'learned': 1093,\n",
       " 'java': 1065,\n",
       " 'programme': 1487,\n",
       " 'common': 324,\n",
       " 'languages': 1080,\n",
       " 'vectors': 2045,\n",
       " 'sub': 1853,\n",
       " 'classing': 292,\n",
       " 'inheritance': 1002,\n",
       " 'template': 1912,\n",
       " 'function': 835,\n",
       " 'stl': 1825,\n",
       " 'defining': 526,\n",
       " 'operator': 1308,\n",
       " 'assessment': 126,\n",
       " 'satisfactory': 1669,\n",
       " 'unsatisfactory': 2013,\n",
       " 'com': 317,\n",
       " 'pleted': 1415,\n",
       " 'completed': 348,\n",
       " 'cs': 472,\n",
       " 'cu': 483,\n",
       " 'basis': 171,\n",
       " 'depending': 544,\n",
       " 'matriculation': 1175,\n",
       " 'year': 2108,\n",
       " 'matriculated': 1174,\n",
       " 'ay2007': 158,\n",
       " '08': 0,\n",
       " 'assessed': 124,\n",
       " 'duration': 624,\n",
       " 'weeks': 2083,\n",
       " 'opening': 1302,\n",
       " 'beginning': 174,\n",
       " 'semesters': 1713,\n",
       " 'abstract': 6,\n",
       " 'interface': 1034,\n",
       " 'new': 1269,\n",
       " 'concept': 372,\n",
       " 'generic': 857,\n",
       " 'approach': 94,\n",
       " 'complex': 352,\n",
       " 'trees': 1978,\n",
       " 'binary': 187,\n",
       " 'search': 1693,\n",
       " 'property': 1503,\n",
       " 'prefix': 1442,\n",
       " 'infix': 998,\n",
       " 'postfix': 1426,\n",
       " 'heaps': 908,\n",
       " 'priority': 1463,\n",
       " 'graphs': 883,\n",
       " 'applications': 88,\n",
       " 'principles': 1462,\n",
       " 'algorithm': 54,\n",
       " 'analysis': 69,\n",
       " 'advanced': 35,\n",
       " 'avl': 155,\n",
       " 'accelerated': 9,\n",
       " 'version': 2052,\n",
       " 'combines': 321,\n",
       " 'follow': 808,\n",
       " 'explores': 747,\n",
       " 'paradigms': 1351,\n",
       " 'integrated': 1016,\n",
       " 'learn': 1091,\n",
       " 'develop': 562,\n",
       " 'medium': 1189,\n",
       " 'scale': 1672,\n",
       " 'software': 1782,\n",
       " 'programs': 1491,\n",
       " 'thousands': 1933,\n",
       " 'lines': 1115,\n",
       " 'code': 307,\n",
       " 'tens': 1914,\n",
       " 'available': 153,\n",
       " 'composition': 358,\n",
       " 'association': 130,\n",
       " 'polymorphism': 1418,\n",
       " 'dynamic': 625,\n",
       " 'binding': 188,\n",
       " 'lambda': 1077,\n",
       " 'expression': 754,\n",
       " 'effect': 636,\n",
       " 'free': 829,\n",
       " 'closures': 299,\n",
       " 'continuations': 415,\n",
       " 'monad': 1227,\n",
       " 'covers': 452,\n",
       " 'objective': 1289,\n",
       " 'familiarise': 776,\n",
       " 'fundamentals': 839,\n",
       " 'devices': 570,\n",
       " 'understand': 2001,\n",
       " 'basics': 170,\n",
       " 'representation': 1618,\n",
       " 'parts': 1365,\n",
       " 'work': 2095,\n",
       " 'separately': 1722,\n",
       " 'allows': 60,\n",
       " 'issues': 1062,\n",
       " 'affect': 43,\n",
       " 'solutions': 1785,\n",
       " 'systems': 1884,\n",
       " 'combinational': 319,\n",
       " 'sequential': 1727,\n",
       " 'circuit': 284,\n",
       " 'techniques': 1904,\n",
       " 'assembly': 123,\n",
       " 'processor': 1476,\n",
       " 'cycles': 493,\n",
       " 'pipelining': 1404,\n",
       " 'memory': 1192,\n",
       " 'hierarchy': 920,\n",
       " 'input': 1005,\n",
       " 'output': 1338,\n",
       " 'aim': 48,\n",
       " 'introduce': 1045,\n",
       " 'necessary': 1256,\n",
       " 'understanding': 2002,\n",
       " 'practice': 1431,\n",
       " 'database': 496,\n",
       " 'management': 1157,\n",
       " 'relational': 1605,\n",
       " 'practical': 1430,\n",
       " 'theoretical': 1926,\n",
       " 'aspects': 121,\n",
       " 'entity': 689,\n",
       " 'relationship': 1606,\n",
       " 'theory': 1928,\n",
       " 'dependencies': 541,\n",
       " 'normalisation': 1278,\n",
       " 'decomposition': 518,\n",
       " 'boyce': 208,\n",
       " 'codd': 306,\n",
       " 'normal': 1277,\n",
       " 'sql': 1807,\n",
       " 'definition': 527,\n",
       " 'manipulation': 1160,\n",
       " 'sublanguages': 1854,\n",
       " 'tuple': 1985,\n",
       " 'calculus': 233,\n",
       " 'domain': 618,\n",
       " 'algebra': 53,\n",
       " 'conceptual': 374,\n",
       " 'analytical': 71,\n",
       " 'systematic': 1883,\n",
       " 'rigorous': 1645,\n",
       " 'main': 1148,\n",
       " 'areas': 108,\n",
       " 'modelling': 1220,\n",
       " 'emphasis': 655,\n",
       " 'modules': 1225,\n",
       " 'cooperatively': 430,\n",
       " 'fulfill': 832,\n",
       " 'requirements': 1625,\n",
       " 'unified': 2006,\n",
       " 'uml': 1994,\n",
       " 'specification': 1798,\n",
       " 'major': 1152,\n",
       " 'engineering': 679,\n",
       " 'modularisation': 1223,\n",
       " 'criteria': 462,\n",
       " 'correctness': 440,\n",
       " 'quality': 1531,\n",
       " 'taken': 1889,\n",
       " 'cs2101': 479,\n",
       " 'effective': 637,\n",
       " 'communication': 328,\n",
       " 'technologists': 1907,\n",
       " 'serve': 1730,\n",
       " 'hundreds': 941,\n",
       " 'provide': 1516,\n",
       " 'appreciation': 92,\n",
       " 'essential': 702,\n",
       " 'logic': 1131,\n",
       " 'constraints': 402,\n",
       " 'concurrent': 379,\n",
       " 'illustrated': 953,\n",
       " 'examples': 718,\n",
       " 'varieties': 2040,\n",
       " 'pascal': 1366,\n",
       " 'smalltalk': 1775,\n",
       " 'scheme': 1681,\n",
       " 'haskell': 905,\n",
       " 'prolog': 1497,\n",
       " 'interpretation': 1041,\n",
       " 'static': 1821,\n",
       " 'semantics': 1711,\n",
       " 'machine': 1145,\n",
       " 'type': 1988,\n",
       " 'inferencing': 996,\n",
       " 'broad': 214,\n",
       " 'networks': 1267,\n",
       " 'appreciations': 93,\n",
       " 'network': 1264,\n",
       " 'range': 1551,\n",
       " 'including': 978,\n",
       " 'protocols': 1511,\n",
       " 'security': 1701,\n",
       " 'teaching': 1899,\n",
       " 'working': 2097,\n",
       " 'integral': 1014,\n",
       " 'tutorials': 1987,\n",
       " 'enforcing': 677,\n",
       " 'learning': 1094,\n",
       " 'given': 866,\n",
       " 'early': 628,\n",
       " 'exposure': 752,\n",
       " 'able': 5,\n",
       " 'complete': 347,\n",
       " 'personal': 1383,\n",
       " 'computers': 370,\n",
       " 'school': 1683,\n",
       " 'facilities': 767,\n",
       " 'operating': 1304,\n",
       " 'links': 1119,\n",
       " 'contemporary': 410,\n",
       " 'unix': 2010,\n",
       " 'linux': 1120,\n",
       " 'windows': 2089,\n",
       " 'focuses': 803,\n",
       " 'os': 1334,\n",
       " 'structuring': 1845,\n",
       " 'architecture': 104,\n",
       " 'concurrency': 378,\n",
       " 'kernel': 1069,\n",
       " 'calls': 236,\n",
       " 'interrupts': 1043,\n",
       " 'models': 1221,\n",
       " 'process': 1473,\n",
       " 'services': 1735,\n",
       " 'scheduling': 1680,\n",
       " 'review': 1639,\n",
       " 'physical': 1398,\n",
       " 'hardware': 903,\n",
       " 'virtual': 2058,\n",
       " 'paging': 1347,\n",
       " 'caches': 229,\n",
       " 'set': 1737,\n",
       " 'deadlock': 506,\n",
       " 'mutual': 1247,\n",
       " 'exclusion': 724,\n",
       " 'synchronisation': 1877,\n",
       " 'mechanisms': 1184,\n",
       " 'metadata': 1197,\n",
       " 'directories': 584,\n",
       " 'operations': 1307,\n",
       " 'discussed': 596,\n",
       " 'digital': 578,\n",
       " 'compression': 362,\n",
       " 'synchronization': 1879,\n",
       " 'image': 956,\n",
       " 'audio': 141,\n",
       " 'video': 2053,\n",
       " 'ii': 949,\n",
       " 'challenges': 262,\n",
       " 'developing': 565,\n",
       " 'media': 1185,\n",
       " 'rich': 1644,\n",
       " 'streaming': 1836,\n",
       " 'retrieval': 1635,\n",
       " 'exposed': 749,\n",
       " 'workings': 2098,\n",
       " 'format': 816,\n",
       " 'taking': 1890,\n",
       " 'confident': 383,\n",
       " 'make': 1153,\n",
       " 'trade': 1957,\n",
       " 'decisions': 515,\n",
       " 'dealing': 508,\n",
       " 'serves': 1733,\n",
       " 'information': 1000,\n",
       " 'illustrates': 954,\n",
       " 'fail': 770,\n",
       " 'malicious': 1155,\n",
       " 'activities': 23,\n",
       " 'protected': 1506,\n",
       " 'places': 1408,\n",
       " 'practices': 1432,\n",
       " 'secure': 1698,\n",
       " 'classical': 288,\n",
       " 'historical': 927,\n",
       " 'ciphers': 283,\n",
       " 'cryptosystems': 471,\n",
       " 'ethical': 704,\n",
       " 'legal': 1099,\n",
       " 'organisational': 1327,\n",
       " 'classic': 287,\n",
       " 'direct': 581,\n",
       " 'attacks': 139,\n",
       " 'validation': 2034,\n",
       " 'vulnerability': 2074,\n",
       " 'attack': 136,\n",
       " 'social': 1779,\n",
       " 'phishing': 1390,\n",
       " 'skills': 1769,\n",
       " 'assurance': 134,\n",
       " 'project': 1493,\n",
       " 'size': 1767,\n",
       " 'multi': 1238,\n",
       " 'person': 1382,\n",
       " 'projects': 1495,\n",
       " 'uses': 2024,\n",
       " 'paradigm': 1350,\n",
       " 'receive': 1574,\n",
       " 'hands': 901,\n",
       " 'commonly': 325,\n",
       " 'used': 2020,\n",
       " 'industry': 993,\n",
       " 'test': 1918,\n",
       " 'automation': 149,\n",
       " 'build': 221,\n",
       " 'revisioning': 1641,\n",
       " 'provides': 1517,\n",
       " 'programmers': 1488,\n",
       " 'viewpoint': 2057,\n",
       " 'overview': 1341,\n",
       " 'field': 786,\n",
       " 'bioinformatics': 191,\n",
       " 'similarity': 1756,\n",
       " 'clustering': 304,\n",
       " 'classification': 289,\n",
       " 'gene': 851,\n",
       " 'recognition': 1578,\n",
       " 'demonstrates': 534,\n",
       " 'role': 1655,\n",
       " 'bioinformaticians': 190,\n",
       " 'bridge': 210,\n",
       " 'biology': 194,\n",
       " 'prepares': 1445,\n",
       " 'relevant': 1608,\n",
       " 'proficient': 1483,\n",
       " 'operators': 1309,\n",
       " 'flow': 800,\n",
       " 'arguments': 109,\n",
       " 'pointers': 1416,\n",
       " 'address': 30,\n",
       " 'arithmetic': 112,\n",
       " 'standard': 1815,\n",
       " 'directory': 585,\n",
       " 'files': 790,\n",
       " 'signals': 1750,\n",
       " 'inter': 1023,\n",
       " 'pipe': 1401,\n",
       " 'fifo': 788,\n",
       " 'terminal': 1915,\n",
       " 'shell': 1747,\n",
       " 'bourne': 207,\n",
       " 'xemacs': 2106,\n",
       " 'gcc': 850,\n",
       " 'ddd': 504,\n",
       " 'debugger': 511,\n",
       " 'regular': 1599,\n",
       " 'text': 1921,\n",
       " 'utilities': 2027,\n",
       " 'grep': 887,\n",
       " 'awk': 156,\n",
       " 'sed': 1702,\n",
       " 'thinking': 1931,\n",
       " 'read': 1561,\n",
       " 'present': 1448,\n",
       " 'research': 1626,\n",
       " 'papers': 1349,\n",
       " 'write': 2103,\n",
       " 'reports': 1616,\n",
       " 'substantial': 1856,\n",
       " 'area': 107,\n",
       " 'logical': 1132,\n",
       " 'deductive': 519,\n",
       " 'reasoning': 1573,\n",
       " 'doing': 616,\n",
       " 'proofs': 1499,\n",
       " 'inductive': 991,\n",
       " 'statistical': 1822,\n",
       " 'fallacies': 774,\n",
       " 'psychological': 1522,\n",
       " 'traps': 1973,\n",
       " 'survey': 1872,\n",
       " 'heuristics': 915,\n",
       " 'creative': 460,\n",
       " 'decision': 514,\n",
       " 'making': 1154,\n",
       " 'reading': 1562,\n",
       " 'addition': 29,\n",
       " 'depth': 546,\n",
       " 'independent': 985,\n",
       " 'opportunity': 1311,\n",
       " 'greater': 885,\n",
       " 'technical': 1902,\n",
       " 'details': 558,\n",
       " 'networking': 1266,\n",
       " 'perform': 1378,\n",
       " 'expriments': 758,\n",
       " 'configuring': 387,\n",
       " 'interconnecting': 1029,\n",
       " 'lans': 1081,\n",
       " 'technologies': 1906,\n",
       " 'routers': 1658,\n",
       " 'switches': 1874,\n",
       " 'sdn': 1691,\n",
       " 'hubs': 936,\n",
       " 'dhcp': 571,\n",
       " 'dns': 612,\n",
       " 'rip': 1646,\n",
       " 'ospf': 1335,\n",
       " 'icmp': 943,\n",
       " 'tcp': 1895,\n",
       " 'udp': 1991,\n",
       " 'wireless': 2091,\n",
       " 'lan': 1078,\n",
       " 'vlan': 2064,\n",
       " 'sip': 1765,\n",
       " 'ssl': 1808,\n",
       " 'ipsec': 1061,\n",
       " 'vpn': 2071,\n",
       " 'tcpdump': 1896,\n",
       " 'netstat': 1263,\n",
       " 'ping': 1400,\n",
       " 'traceroute': 1955,\n",
       " 'layer': 1086,\n",
       " 'client': 295,\n",
       " 'server': 1731,\n",
       " 'p2p': 1342,\n",
       " 'socket': 1780,\n",
       " 'life': 1106,\n",
       " 'cycle': 492,\n",
       " 'sdlc': 1690,\n",
       " 'experience': 731,\n",
       " 'groups': 892,\n",
       " 'designed': 553,\n",
       " 'tested': 1919,\n",
       " 'large': 1082,\n",
       " 'scaled': 1673,\n",
       " 'applying': 90,\n",
       " 'best': 182,\n",
       " 'user': 2022,\n",
       " 'needs': 1259,\n",
       " 'meet': 1190,\n",
       " 'according': 15,\n",
       " 'efficient': 642,\n",
       " 'components': 357,\n",
       " 'integration': 1017,\n",
       " 'apply': 89,\n",
       " 'current': 487,\n",
       " 'practise': 1433,\n",
       " 'active': 22,\n",
       " 'independently': 986,\n",
       " 'group': 890,\n",
       " 'significant': 1753,\n",
       " 'related': 1603,\n",
       " 'analyzing': 75,\n",
       " 'designing': 555,\n",
       " 'implementing': 966,\n",
       " 'attacking': 138,\n",
       " 'defending': 523,\n",
       " 'classroom': 293,\n",
       " 'gain': 842,\n",
       " 'problems': 1470,\n",
       " 'parallel': 1352,\n",
       " 'real': 1565,\n",
       " 'machines': 1146,\n",
       " 'divided': 609,\n",
       " 'computation': 365,\n",
       " 'parallelism': 1354,\n",
       " 'architectures': 105,\n",
       " 'shared': 1745,\n",
       " 'distributed': 604,\n",
       " 'rchitectures': 1558,\n",
       " 'interconnection': 1030,\n",
       " 'topologies': 1952,\n",
       " 'performance': 1379,\n",
       " 'scalability': 1670,\n",
       " 'grid': 888,\n",
       " 'cloud': 300,\n",
       " 'gpgpu': 872,\n",
       " 'consists': 398,\n",
       " 'executes': 726,\n",
       " 'simultaneously': 1763,\n",
       " 'collaborate': 312,\n",
       " 'synchronising': 1878,\n",
       " 'programmes': 1489,\n",
       " 'sets': 1738,\n",
       " 'collaborating': 313,\n",
       " 'gained': 843,\n",
       " 'specifying': 1800,\n",
       " 'properties': 1502,\n",
       " 'asynchronous': 135,\n",
       " 'knowledge': 1073,\n",
       " 'skill': 1768,\n",
       " 'discusses': 597,\n",
       " 'scope': 1686,\n",
       " 'parameter': 1355,\n",
       " 'passing': 1368,\n",
       " 'compilation': 339,\n",
       " 'discussion': 598,\n",
       " 'highlights': 924,\n",
       " 'level': 1100,\n",
       " 'hierarchical': 918,\n",
       " 'automatic': 147,\n",
       " 'feature': 782,\n",
       " 'product': 1479,\n",
       " 'teams': 1901,\n",
       " 'friendly': 831,\n",
       " 'production': 1480,\n",
       " 'world': 2101,\n",
       " 'support': 1865,\n",
       " 'goal': 868,\n",
       " 'closely': 298,\n",
       " 'users': 2023,\n",
       " 'gather': 849,\n",
       " 'obtain': 1291,\n",
       " 'feedback': 784,\n",
       " 'rapid': 1553,\n",
       " 'iterative': 1063,\n",
       " 'markets': 1166,\n",
       " 'growing': 893,\n",
       " 'base': 166,\n",
       " 'deployment': 545,\n",
       " 'web': 2081,\n",
       " 'validating': 2033,\n",
       " 'ui': 1992,\n",
       " 'ux': 2030,\n",
       " 'platforms': 1413,\n",
       " 'mobile': 1214,\n",
       " 'building': 222,\n",
       " 'competencies': 336,\n",
       " 'trains': 1962,\n",
       " 'individual': 989,\n",
       " 'final': 791,\n",
       " 'team': 1900,\n",
       " 'smart': 1776,\n",
       " 'phones': 1391,\n",
       " 'tablets': 1886,\n",
       " 'equipped': 696,\n",
       " 'increasing': 982,\n",
       " 'number': 1286,\n",
       " 'sensing': 1719,\n",
       " 'modalities': 1217,\n",
       " 'traditional': 1958,\n",
       " 'keyboards': 1071,\n",
       " 'touch': 1953,\n",
       " 'screens': 1687,\n",
       " 'cameras': 238,\n",
       " 'microphones': 1205,\n",
       " 'inertial': 994,\n",
       " 'sensor': 1720,\n",
       " 'gps': 873,\n",
       " 'receivers': 1575,\n",
       " 'packed': 1345,\n",
       " 'single': 1764,\n",
       " 'platform': 1412,\n",
       " 'important': 968,\n",
       " 'empower': 662,\n",
       " 'developers': 564,\n",
       " 'theories': 1927,\n",
       " 'needed': 1258,\n",
       " 'multimodal': 1240,\n",
       " 'key': 1070,\n",
       " 'accompany': 14,\n",
       " 'proven': 1515,\n",
       " 'architectural': 103,\n",
       " 'perspective': 1384,\n",
       " 'requirement': 1624,\n",
       " 'elicitation': 649,\n",
       " 'sound': 1790,\n",
       " 'exploration': 745,\n",
       " 'patterns': 1371,\n",
       " 'explicate': 739,\n",
       " 'replicable': 1614,\n",
       " 'form': 814,\n",
       " 'concerned': 376,\n",
       " 'involving': 1058,\n",
       " 'improve': 972,\n",
       " 'considers': 395,\n",
       " 'principle': 1461,\n",
       " 'instruction': 1010,\n",
       " 'pipeline': 1402,\n",
       " 'risc': 1647,\n",
       " 'vector': 2044,\n",
       " 'examined': 714,\n",
       " 'iii': 950,\n",
       " 'builds': 223,\n",
       " 'foundation': 824,\n",
       " 'formed': 818,\n",
       " 'cs2106': 480,\n",
       " 'extends': 760,\n",
       " 'focus': 802,\n",
       " 'actual': 24,\n",
       " 'pragmatics': 1436,\n",
       " 'drawn': 621,\n",
       " 'interfaces': 1035,\n",
       " 'threads': 1935,\n",
       " 'interprocess': 1042,\n",
       " 'device': 569,\n",
       " 'characteristics': 272,\n",
       " 'mapped': 1163,\n",
       " 'special': 1796,\n",
       " 'purpose': 1527,\n",
       " 'storage': 1827,\n",
       " 'access': 11,\n",
       " 'query': 1536,\n",
       " 'optimisation': 1315,\n",
       " 'environments': 694,\n",
       " 'transactions': 1964,\n",
       " 'currency': 486,\n",
       " 'recovery': 1582,\n",
       " 'useful': 2021,\n",
       " 'extension': 761,\n",
       " 'databases': 497,\n",
       " 'deal': 507,\n",
       " 'warehousing': 2077,\n",
       " 'mining': 1211,\n",
       " 'discovery': 591,\n",
       " 'online': 1298,\n",
       " 'sequencing': 1726,\n",
       " 'genomes': 861,\n",
       " 'stage': 1812,\n",
       " 'mystery': 1248,\n",
       " 'body': 203,\n",
       " 'need': 1257,\n",
       " 'encoded': 668,\n",
       " 'genome': 860,\n",
       " 'rna': 1648,\n",
       " 'protein': 1508,\n",
       " 'cover': 448,\n",
       " 'annotation': 77,\n",
       " 'motif': 1233,\n",
       " 'identification': 946,\n",
       " 'proteomics': 1509,\n",
       " 'population': 1420,\n",
       " 'genetics': 859,\n",
       " 'microarray': 1203,\n",
       " 'tied': 1937,\n",
       " 'technology': 1908,\n",
       " 'end': 673,\n",
       " 'expected': 730,\n",
       " 'appreciate': 91,\n",
       " 'underlying': 2000,\n",
       " 'different': 574,\n",
       " 'analysing': 68,\n",
       " 'framework': 828,\n",
       " 'example': 717,\n",
       " 'lower': 1143,\n",
       " 'bound': 205,\n",
       " 'average': 154,\n",
       " 'case': 249,\n",
       " 'np': 1285,\n",
       " 'completeness': 349,\n",
       " 'purposes': 1528,\n",
       " 'ability': 4,\n",
       " 'prepare': 1443,\n",
       " 'upper': 2015,\n",
       " 'bounds': 206,\n",
       " 'recurrences': 1583,\n",
       " 'prune': 1519,\n",
       " 'branch': 209,\n",
       " 'graph': 880,\n",
       " 'traversal': 1974,\n",
       " 'randomised': 1547,\n",
       " 'approaches': 95,\n",
       " 'amortised': 65,\n",
       " 'selected': 1707,\n",
       " 'competitive': 338,\n",
       " 'challenging': 263,\n",
       " 'divide': 608,\n",
       " 'conquer': 391,\n",
       " 'greedy': 886,\n",
       " 'backtracking': 161,\n",
       " 'specific': 1797,\n",
       " 'like': 1111,\n",
       " 'geometry': 864,\n",
       " 'string': 1839,\n",
       " 'theoretic': 1925,\n",
       " 'ai': 47,\n",
       " 'deepening': 521,\n",
       " 'heuristic': 914,\n",
       " 'included': 976,\n",
       " 'toolkits': 1947,\n",
       " 'supported': 1866,\n",
       " 'solution': 1784,\n",
       " 'representative': 1620,\n",
       " 'known': 1074,\n",
       " 'non': 1274,\n",
       " 'logics': 1133,\n",
       " 'means': 1179,\n",
       " 'verifying': 2051,\n",
       " 'emphasizes': 658,\n",
       " 'contrast': 419,\n",
       " 'similar': 1755,\n",
       " 'courses': 447,\n",
       " 'represent': 1617,\n",
       " 'representations': 1619,\n",
       " 'correct': 438,\n",
       " 'executed': 725,\n",
       " 'modal': 1216,\n",
       " 'treatments': 1976,\n",
       " 'predicate': 1438,\n",
       " 'temporal': 1913,\n",
       " 'fully': 834,\n",
       " 'verification': 2049,\n",
       " 'discussions': 599,\n",
       " 'following': 810,\n",
       " 'intrusion': 1051,\n",
       " 'detection': 560,\n",
       " 'electronic': 646,\n",
       " 'mail': 1147,\n",
       " 'authentication': 143,\n",
       " 'buffer': 218,\n",
       " 'overflow': 1339,\n",
       " 'stack': 1810,\n",
       " 'protection': 1507,\n",
       " 'instance': 1009,\n",
       " 'quantified': 1533,\n",
       " 'quantification': 1532,\n",
       " 'tells': 1911,\n",
       " 'compress': 360,\n",
       " 'transmit': 1971,\n",
       " 'error': 699,\n",
       " 'correcting': 439,\n",
       " 'cryptography': 469,\n",
       " 'entropy': 692,\n",
       " 'measures': 1182,\n",
       " 'limits': 1113,\n",
       " 'noisy': 1273,\n",
       " 'channel': 267,\n",
       " 'commitments': 323,\n",
       " 'distribution': 605,\n",
       " 'randomness': 1550,\n",
       " 'extraction': 765,\n",
       " 'internet': 1038,\n",
       " 'things': 1929,\n",
       " 'iot': 1059,\n",
       " 'embedded': 652,\n",
       " 'power': 1428,\n",
       " 'sensors': 1721,\n",
       " 'connect': 389,\n",
       " 'seamless': 1692,\n",
       " 'cooperation': 428,\n",
       " 'cyber': 490,\n",
       " 'revolutionizing': 1643,\n",
       " 'lives': 1127,\n",
       " 'holistic': 931,\n",
       " 'view': 2055,\n",
       " 'entire': 687,\n",
       " 'spectrum': 1801,\n",
       " 'fog': 807,\n",
       " 'balance': 162,\n",
       " 'bandwidth': 165,\n",
       " 'safety': 1665,\n",
       " 'component': 356,\n",
       " 'intended': 1022,\n",
       " 'disciplines': 587,\n",
       " 'human': 938,\n",
       " 'interaction': 1026,\n",
       " 'stresses': 1837,\n",
       " 'importance': 967,\n",
       " 'centred': 258,\n",
       " 'usability': 2016,\n",
       " 'acquire': 19,\n",
       " 'laboratory': 1076,\n",
       " 'exercises': 728,\n",
       " 'hci': 906,\n",
       " 'contextual': 414,\n",
       " 'factors': 769,\n",
       " 'teaches': 1898,\n",
       " 'graphics': 882,\n",
       " 'reviews': 1640,\n",
       " 'mathematics': 1173,\n",
       " 'completing': 350,\n",
       " 'terminology': 1916,\n",
       " 'implement': 962,\n",
       " '2d': 1,\n",
       " '3d': 2,\n",
       " 'interactive': 1028,\n",
       " 'enrichment': 684,\n",
       " 'introduced': 1046,\n",
       " 'art': 115,\n",
       " 'viewing': 2056,\n",
       " 'interesting': 1032,\n",
       " 'clips': 297,\n",
       " 'experimenting': 735,\n",
       " 'demo': 533,\n",
       " 'animation': 76,\n",
       " 'easily': 629,\n",
       " 'manipulate': 1159,\n",
       " 'deformation': 528,\n",
       " 'lighting': 1109,\n",
       " 'rendering': 1613,\n",
       " 'create': 457,\n",
       " 'appealing': 84,\n",
       " 'scenes': 1679,\n",
       " 'coordinate': 431,\n",
       " 'spaces': 1794,\n",
       " 'transforms': 1968,\n",
       " 'procedural': 1471,\n",
       " 'particle': 1361,\n",
       " 'character': 268,\n",
       " 'shading': 1741,\n",
       " 'scripting': 1688,\n",
       " 'artificial': 117,\n",
       " 'intelligence': 1019,\n",
       " 'covering': 451,\n",
       " 'turing': 1986,\n",
       " 'blind': 199,\n",
       " 'minimax': 1210,\n",
       " 'alpha': 61,\n",
       " 'beta': 183,\n",
       " 'procedures': 1472,\n",
       " 'resolution': 1627,\n",
       " 'refutation': 1594,\n",
       " 'monotonic': 1229,\n",
       " 'assumption': 133,\n",
       " 'truth': 1983,\n",
       " 'maintenance': 1151,\n",
       " 'hierarchies': 919,\n",
       " 'frame': 826,\n",
       " 'certainly': 260,\n",
       " 'bayes': 172,\n",
       " 'rule': 1662,\n",
       " 'frames': 827,\n",
       " 'semantic': 1710,\n",
       " 'nets': 1262,\n",
       " 'planning': 1410,\n",
       " 'natural': 1252,\n",
       " 'vision': 2061,\n",
       " 'expert': 737,\n",
       " 'lisp': 1121,\n",
       " 'neural': 1268,\n",
       " 'reason': 1571,\n",
       " 'studying': 1851,\n",
       " 'better': 184,\n",
       " 'extract': 763,\n",
       " 'regularities': 1600,\n",
       " 'raw': 1556,\n",
       " 'ultimate': 1993,\n",
       " 'self': 1709,\n",
       " 'relieve': 1611,\n",
       " 'humans': 940,\n",
       " 'tasks': 1893,\n",
       " 'familiar': 775,\n",
       " 'capable': 242,\n",
       " 'capturing': 245,\n",
       " 'representing': 1621,\n",
       " 'storing': 1829,\n",
       " 'organizing': 1331,\n",
       " 'retrieving': 1637,\n",
       " 'unstructured': 2014,\n",
       " 'loosely': 1139,\n",
       " 'structured': 1843,\n",
       " 'aspect': 120,\n",
       " 'document': 613,\n",
       " 'indexing': 988,\n",
       " 'documents': 614,\n",
       " 'semi': 1714,\n",
       " 'newswire': 1270,\n",
       " 'stories': 1828,\n",
       " 'transcribed': 1965,\n",
       " 'speech': 1803,\n",
       " 'email': 650,\n",
       " 'blogs': 201,\n",
       " 'images': 957,\n",
       " 'critical': 463,\n",
       " 'engines': 680,\n",
       " 'subsequent': 1855,\n",
       " 'particular': 1362,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizer(stop_words = 'english').fit(courses['info']).vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the info column, although we have removed the stopwords, there are still many useless words like \"first, also, using\" that appears many times. These words are making our clustering less effective. In order to improve the model's performance, we need to do more work on info and remove these useless words while keep some specific nouns."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
